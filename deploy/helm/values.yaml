# Default values for kubeblocks
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Enabled this if you wish to install controller deployment
replicaCount: 1

image:
  repository: docker.io/apecloud/kubeblocks
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

loggerSettings:
  # Development Mode defaults(encoder=consoleEncoder,logLevel=Debug,stackTraceLevel=Warn).
  # Production Mode defaults(encoder=jsonEncoder,logLevel=Info,stackTraceLevel=Error) (default false)
  developmentMode: false
  # log encoding (one of 'json' or 'console')
  encoder: console
  # log level, can be one of 'debug', 'info', 'error', or any integer value > 0 
  # which corresponds to custom debug levels of increasing verbosity.
  level:
  # Zap time encoding (one of 'epoch', 'millis', 'nano', 'iso8601', 'rfc3339' or 
  # 'rfc3339nano'). Defaults to 'iso8601'.
  timeEncoding: 'iso8601'

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL

podSecurityContext:
  runAsNonRoot: true
  # readOnlyRootFilesystem: true
  # runAsUser: 1000
  # fsGroup: 2000
  # TODO(user): For common cases that do not require escalating privileges
  # it is recommended to ensure that all your Pods/Containers are restrictive.
  # More info: https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted
  # Please uncomment the following code if your project does NOT have to work on old Kubernetes
  # versions < 1.19 or on vendors versions which do NOT support this field by default (i.e. Openshift < 4.11 ).
  # seccompProfile:
  #   type: RuntimeDefault

service:
  type: ClusterIP
  port: 9443
  # -- Service node port.
  # Only used if `service.type` is `NodePort`.
  nodePort:


## Metrics serviceMonitor parameters
## Enable this if you're using Prometheus Operator
##
serviceMonitor:
  enabled: false
  # metrics server will be exposed at this port.
  port: 8080
  # Only used if `service.type` is `NodePort`.
  nodePort:

# -- Topology spread constraints.
topologySpreadConstraints: []

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # TODO(user): Configure the resources accordingly based on the project requirements.
  # More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # limits:
  #   cpu: 500m
  #   memory: 128Mi
  # requests:
  #   cpu: 10m
  #   memory: 64Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

podDisruptionBudget:
  minAvailable: 1
  maxUnavailable:

admissionWebhooks:
  enabled: true
  createSelfSignedCert: true

dashboards:
  ## If false, dashboards will not be installed
  ##
  enabled: false

## Data protection settings
##
dataProtection:
  ## @param dataProtection.enableVolumeSnapshot - set this to true if cluster does have snapshot.storage.k8s.io API installed
  ##
  enableVolumeSnapshot: false
  ## @param dataProtection.backupSchedule -- set backup policy schedule time
  ## backupSchedule is in Cron format, the timezone is in UTC. see https://en.wikipedia.org/wiki/Cron.
  ## Example: 0 2 * * *  -- backup job will be scheduled to start at 2:00 each day.
  ##
  backupSchedule: ""
  ## @param dataProtection.backupTTL -- set backup time to live.
  ## backupTTL is a time.Duration-parseable string describing how long.
  ## Example: 168h0m0s  -- the backup will expire in 7 days.
  ##
  backupTTL: ""


# Sub-charts
prometheus:
  ## If false, prometheus sub-chart will not be installed
  ##
  enabled: false

  alertmanager:
    ## If false, alertmanager will not be installed
    ##
    enabled: true

    persistentVolume:
      ## If true, alertmanager will create/use a Persistent Volume Claim
      ## If false, use emptyDir
      ##
      enabled: false

      ## alertmanager data Persistent Volume size
      ##
      size: 2Gi

  kubeStateMetrics:
    ## If false, kube-state-metrics sub-chart will not be installed
    ##
    enabled: false

  nodeExporter:
    ## If false, node-exporter will not be installed
    ##
    enabled: false

  server:
    ## Prometheus server container name
    ##
    enabled: true

    global:
      ## How frequently to scrape targets by default
      ##
      scrape_interval: 30s
      ## How long until a scrape request times out
      ##
      scrape_timeout: 10s
      ## How frequently to evaluate rules
      ##
      evaluation_interval: 30s

    ## Prefix used to register routes, overriding externalUrl route.
    ## Useful for proxies that rewrite URLs.
    ##
    routePrefix: /

    persistentVolume:
      ## If true, Prometheus server will create/use a Persistent Volume Claim
      ## If false, use emptyDir
      ##
      enabled: false

      ## Prometheus server data Persistent Volume size
      ##
      size: 8Gi

  serverFiles:
    prometheus.yml:
      scrape_configs:
        - job_name: prometheus
          static_configs:
            - targets:
                - localhost:9090

        # Scrape config for API servers.
        #
        # Kubernetes exposes API servers as endpoints to the default/kubernetes
        # service so this uses `endpoints` role and uses relabelling to only keep
        # the endpoints associated with the default/kubernetes service using the
        # default named port `https`. This works for single API server deployments as
        # well as HA API server deployments.
        - job_name: 'kubernetes-apiservers'

          kubernetes_sd_configs:
            - role: endpoints

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          # Keep only the default/kubernetes service endpoints for the https port. This
          # will add targets for each API server which Kubernetes adds an endpoint to
          # the default/kubernetes service.
          relabel_configs:
            - source_labels: [ __meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name ]
              action: keep
              regex: default;kubernetes;https

        - job_name: 'kubernetes-nodes'

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
            - role: node

          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [ __meta_kubernetes_node_name ]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/$1/proxy/metrics

        - job_name: 'kubernetes-nodes-cadvisor'

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
            - role: node

          # This configuration will work only on kubelet 1.7.3+
          # As the scrape endpoints for cAdvisor have changed
          # if you are using older version you need to change the replacement to
          # replacement: /api/v1/nodes/$1:4194/proxy/metrics
          # more info here https://github.com/coreos/prometheus-operator/issues/633
          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [ __meta_kubernetes_node_name ]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor

        # Example scrape config for pods
        #
        # The relabeling allows the actual pod scrape endpoint to be configured via the
        # following annotations:
        #
        # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`,
        # except if `prometheus.io/scrape-slow` is set to `true` as well.
        # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
        # to set this to `https` & most likely set the `tls_config` of the scrape config.
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
        - job_name: 'kubernetes-pods'
          honor_labels: true

          kubernetes_sd_configs:
            - role: pod

          relabel_configs:
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape ]
              action: keep
              regex: true
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow ]
              action: drop
              regex: true
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scheme ]
              action: replace
              regex: (https?)
              target_label: __scheme__
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_path ]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [ __address__, __meta_kubernetes_pod_annotation_prometheus_io_port ]
              action: replace
              regex: (.+?)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__
            - action: labelmap
              regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
              replacement: __param_$1
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_controller_(.+)
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_statefulset_(.+)
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_cs_(.+)
            - action: labelmap
              regex: __meta_kubernetes_pod_label_(.+)
            - source_labels: [ __meta_kubernetes_namespace ]
              action: replace
              target_label: namespace
            - source_labels: [ __meta_kubernetes_pod_name ]
              action: replace
              target_label: pod
            - source_labels: [ __meta_kubernetes_pod_phase ]
              regex: Pending|Succeeded|Failed|Completed
              action: drop

        # Example Scrape config for pods which should be scraped slower. An useful example
        # would be stackriver-exporter which queries an API on every scrape of the pod
        #
        # The relabeling allows the actual pod scrape endpoint to be configured via the
        # following annotations:
        #
        # * `prometheus.io/scrape-slow`: Only scrape pods that have a value of `true`
        # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
        # to set this to `https` & most likely set the `tls_config` of the scrape config.
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
        - job_name: 'kubernetes-pods-slow'
          honor_labels: true

          scrape_interval: 5m
          scrape_timeout: 30s

          kubernetes_sd_configs:
            - role: pod

          relabel_configs:
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow ]
              action: keep
              regex: true
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scheme ]
              action: replace
              regex: (https?)
              target_label: __scheme__
            - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_path ]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [ __address__, __meta_kubernetes_pod_annotation_prometheus_io_port ]
              action: replace
              regex: (.+?)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__
            - action: labelmap
              regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
              replacement: __param_$1
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_controller_(.+)
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_statefulset_(.+)
            - action: labeldrop
              regex: __meta_kubernetes_pod_label_cs_(.+)
            - action: labelmap
              regex: __meta_kubernetes_pod_label_(.+)
            - source_labels: [ __meta_kubernetes_namespace ]
              action: replace
              target_label: namespace
            - source_labels: [ __meta_kubernetes_pod_name ]
              action: replace
              target_label: pod
            - source_labels: [ __meta_kubernetes_pod_phase ]
              regex: Pending|Succeeded|Failed|Completed
              action: drop

  pushgateway:
    ## If false, pushgateway will not be installed
    ##
    enabled: false

grafana:
  ## If false, grafana sub-chart will not be installed
  ##
  enabled: false

  ## Timezone for the default dashboards
  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg
  ##
  defaultDashboardsTimezone:

  adminUser: admin
  adminPassword: abc

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"

    datasources:
      enabled: true
      label: grafana_datasource
      labelValue: "1"

      defaultDatasourceEnabled: true
      uid: prometheus

      skipReload: true
      initDatasources: true

  testFramework:
    enabled: false

  grafana.ini:
    # Basic auth is enabled by default and works with the builtin Grafana user password authentication system and LDAP authentication integration.
    auth.basic:
      enabled: false

    auth.anonymous:
      enabled: true
      # Hide the Grafana version text from the footer and help tooltip for unauthenticated users (default: false)
      hide_version: true

loadbalancer:
  enabled: false


wesql:
  enabled: true

## snapshot-controller settings
## ref: https://artifacthub.io/packages/helm/piraeus-charts/snapshot-controller#configuration
##
snapshot-controller:
  ## @param snapshot-controller.enabled -- Enable snapshot-controller chart.
  ##
  enabled: false
  ## @param snapshot-controller.replicaCount -- Number of replicas to deploy.
  ##
  replicaCount: 1
  ## snapshot-controller image setting, easy access for CN users.
  ## @param snapshot-controller.image.repository -- Repository to pull the image from.
  ##
  image:
    repository: registry.aliyuncs.com/google_containers/snapshot-controller

## csi-s3 settings
## ref: https://artifacthub.io/packages/helm/cloudve/csi-s3#configuration
##
csi-s3:
  ## @param csi-s3.enabled -- Enable csi-s3 chart.
  enabled: false
  ## csi-s3 secret settings
  ## @param csi-s3.secret.accessKey -- S3 Access Key.
  ## @param csi-s3.secret.secretKey -- S3 Secret Key.
  ## @param csi-s3.secret.endpoint -- S3 Endpoint.
  ##
  secret:
    accessKey: ""
    secretKey: ""
    endpoint: ""
  ## csi-s3 storageClass setting
  ## @param csi-s3.storageClass.create -- Specifies whether the storage class should be created.
  ## @param csi-s3.storageClass.singleBucket -- Use a single bucket for all dynamically provisioned persistent volumes.
  ## @param csi-s3.storageClass.mountOptions -- mount options.
  ##
  storageClass:
    create: true
    singleBucket: ""
    mountOptions: "--memory-limit 1000 --dir-mode 0777 --file-mode 0666 --region cn-northwest-1"
