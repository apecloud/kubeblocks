apiVersion: apps.kubeblocks.io/v1alpha1
kind: ClusterDefinition
metadata:
  name: apecloud-clickhouse
  labels:
    {{- include "kafka.labels" . | nindent 4 }}
    {{- if .Values.commonLabels }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonLabels "context" $ ) | nindent 4 }}
    {{- end }}
  {{- if .Values.commonAnnotations }}
  annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
  {{- end }}
spec:
  connectionCredential:
    superusers: "User:admin"
    endpoint: "$(SVC_FQDN):$(SVC_PORT_kafka-controller)"

  componentDefs:
    # combined both controller(kraft) and broker. Ref: https://kafka.apache.org/documentation/#kraft_role
    - name: kafka-server
      description: |-
        Kafka servers that act as both brokers and controllers are referred to as "combined" servers. Combined servers
        are simpler to operate for small use cases like a development environment. The key disadvantage is that the
        controller will be less isolated from the rest of the system. For example, it is not possible to roll or scale
        the controllers separately from the brokers in combined mode. Combined mode is not recommended in critical
        deployment environments.
      workloadType: Stateful
      characterType: kafka
      maxUnavailable: 49%
      probes:
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 5556
      configSpec:
        configTemplateRefs:
          - name: kafka-configuration-tpl
            configTplRef: kafka-configuration-tpl
            volumeName: kafka-config
            namespace: {{ .Release.Namespace }}
          - name: kafka-scripts-tpl
            configTplRef: kafka-scripts-tpl
            volumeName: scripts
            namespace: {{ .Release.Namespace }}
            defaultMode: 0755
      service:
        ports:
          - name: kafka-client
            targetPort: kafka-client
            port: 9092
            nodePort: null
          - name: kafka-controller
            targetPort: kafka-controller
            port: 9093
            nodePort: null
          - name: metrics
            targetPort: metrics
            port: 5556
            nodePort: null

      podSpec:
        securityContext:
          fsGroup: 1001
          
        containers:
          - name: kafka
            image: docker.io/bitnami/kafka:3.4.0-debian-11-r2
            imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
            securityContext:
              allowPrivilegeEscalation: false
              runAsNonRoot: true
              runAsUser: 1001
            command:
              - /scripts/kafka-server-setup.sh
            env:
              - name: BITNAMI_DEBUG
                value: "false"
              - name: MY_POD_IP
                value: "$(KB_PODIP)"
                # value: "$(KB_POD_IP)"
              - name: MY_POD_NAME
                value: "$(KB_POD_NAME)"
              - name: KAFKA_ENABLE_KRAFT
                value: "yes"
              - name: KAFKA_CFG_PROCESS_ROLES
                value: "broker,controller"
              - name: KAFKA_CFG_LISTENERS
                value: "CONTROLLER://:9093,INTERNAL://:9094,CLIENT://:9092"
              - name: KAFKA_INTER_BROKER_LISTENER_NAME
                value: "INTERNAL"
              - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
                value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
              - name: KAFKA_CFG_ADVERTISED_LISTENERS
                value: "INTERNAL://$(KB_POD_NAME).$(KB_CLUSTER_COMP_NAME)-headless.$(KB_CLUSTER_NAME).svc:9094,CLIENT://$(KB_POD_NAME).$(KB_CLUSTER_COMP_NAME)-headless.$(KB_CLUSTER_NAME).svc:9092"
                # value: "INTERNAL://$(KB_POD_FQDN):9094,CLIENT://$(KB_POD_FQDN):9092"
              - name: ALLOW_PLAINTEXT_LISTENER
                value: "yes"
              - name: KAFKA_ZOOKEEPER_PROTOCOL
                value: PLAINTEXT
              - name: JMX_PORT
                value: "5555"
              - name: KAFKA_VOLUME_DIR
                value: "/bitnami/kafka"
              - name: KAFKA_CFG_LOG_DIRS
                value: "/bitnami/kafka/data"
              - name: KAFKA_LOG_DIR
                value: "/opt/bitnami/kafka/logs"
              - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
                value: "false"
              - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
                value: "true"
              - name: KAFKA_HEAP_OPTS
                value: "-Xmx1024m -Xms1024m"
              - name: KAFKA_CFG_SUPER_USERS
                valueFrom:
                  secretKeyRef:
                    # notes: could also reference the secret's 'password' key,
                    # just keeping the same secret keys as bitnami Clickhouse chart
                    name: $(CONN_CREDENTIAL_SECRET_NAME)
                    key: superusers

            ports:
              - name: kafka-client
                containerPort: 9092
              - name: kafka-controller
                containerPort: 9093
              - name: kafka-internal
                containerPort: 9094
            livenessProbe:
              failureThreshold: 3
              initialDelaySeconds: 10
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 5
              tcpSocket:
                port: kafka-client
            readinessProbe:
              failureThreshold: 6
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 5
              tcpSocket:
                port: kafka-client
            volumeMounts:
              - name: data
                mountPath: /bitnami/kafka
              - name: logs
                mountPath: /opt/bitnami/kafka/logs
              - name: scripts
                mountPath: /scripts/kafka-server-setup.sh
                subPath: kafka-server-setup.sh
              - name: kafka-config
                mountPath: /bitnami/kafka/config/server.properties
                subPath: server.properties

          - name: jmx-exporter
            image: docker.io/bitnami/jmx-exporter:0.17.2-debian-11-r49
            imagePullPolicy: {{ default "IfNotPresent" .Values.images.pullPolicy }}
            securityContext:
              runAsNonRoot: true
              runAsUser: 1001
            command:
              - java
            args:
              - -XX:MaxRAMPercentage=100
              - -XshowSettings:vm
              - -jar
              - jmx_prometheus_httpserver.jar
              - "5556"
              - /etc/jmx-kafka/jmx-kafka-prometheus.yml
            ports:
              - name: metrics
                containerPort: 5556
            volumeMounts:
              - name: jmx-config
                mountPath: /etc/jmx-kafka

    - name: kafka-exporter
      workloadType: Stateless
      configSpec:
        configTemplateRefs:
          - name: kafka-scripts-tpl
            configTplRef: kafka-scripts-tpl
            volumeName: scripts
            namespace: {{ .Release.Namespace }}
            defaultMode: 0755
      probes:
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9308
      service:
        ports:
          - name: metrics
            targetPort: metrics
            port: 9308
      podSpec:
        securityContext:
          fsGroup: 1001
        containers:
          - name: kafka-exporter
            image: docker.io/bitnami/kafka-exporter:1.6.0-debian-11-r61
            imagePullPolicy: {{ default .Values.images.pullPolicy "IfNotPresent" }}
            securityContext:
              runAsNonRoot: true
              runAsUser: 1001
            command:
              - /scripts/setup.sh
            ports:
              - name: metrics
                containerPort: 9308
            volumeMounts:
              - name: scripts
                mountPath: /scripts/setup.sh
                subPath: kafka-exporter-setup.sh