#################################################################################
######  INFO: BREAK A LEG IN YOUR GAME TODAY!!!                             #####
#################################################################################
{{ include "_logo" . | indent 2 }}
{{ template "_divider" }}
{{ if .Values.prometheus.server.enabled }}
The Prometheus Server can be accessed via port {{ .Values.prometheus.server.service.servicePort }} on the following DNS name from within your cluster:

    {{ template "monitor.prometheus.server.fullname" . }}.{{ template "monitor.prometheus.namespace" . }}.svc.cluster.local
{{ if .Values.prometheus.server.ingress.enabled -}}
From outside the cluster, the prometheus server URL(s) are:

{{- range .Values.prometheus.server.ingress.hosts }}
    http://{{ . }}
{{- end }}
{{- else }}
Get the Prometheus Server URL by running these commands in the same shell:

{{- if contains "NodePort" .Values.prometheus.server.service.type }}

    export NODE_PORT=$(kubectl get --namespace {{ template "monitor.prometheus.namespace" . }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ template "monitor.prometheus.server.fullname" . }})
    export NODE_IP=$(kubectl get nodes --namespace {{ template "monitor.prometheus.namespace" . }} -o jsonpath="{.items[0].status.addresses[0].address}")
    echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.prometheus.server.service.type }}

    NOTE: It may take a few minutes for the LoadBalancer IP to be available.
          You can watch the status of by running 'kubectl get svc --namespace {{ template "monitor.prometheus.namespace" . }} -w {{ template "monitor.prometheus.server.fullname" . }}'

    export SERVICE_IP=$(kubectl get svc --namespace {{ template "monitor.prometheus.namespace" . }} {{ template "monitor.prometheus.server.fullname" . }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo http://$SERVICE_IP:{{ .Values.prometheus.server.service.servicePort }}
{{- else if contains "ClusterIP"  .Values.prometheus.server.service.type }}

    export POD_NAME=$(kubectl get pods --namespace {{ template "monitor.prometheus.namespace" . }} -l "app=prometheus,component={{ .Values.prometheus.server.name }}" -o jsonpath="{.items[0].metadata.name}")
    kubectl --namespace {{ template "monitor.prometheus.namespace" . }} port-forward $POD_NAME 9090
{{- end }}
{{- end }}

{{- if .Values.prometheus.server.persistentVolume.enabled }}
{{- else }}

#################################################################################
######   WARNING: Persistence is disabled!!! You will lose your data when   #####
######            the Prometheus Server pod is terminated.                  #####
#################################################################################

{{- end }}
{{- end }}

{{ template "_divider" }}
{{ if .Values.prometheus.alertmanager.enabled }}
The Prometheus Alertmanager can be accessed via port {{ .Values.prometheus.alertmanager.service.servicePort }} on the following DNS name from within your cluster:

    {{ template "monitor.prometheus.alertmanager.fullname" . }}.{{ template "monitor.prometheus.namespace" . }}.svc.cluster.local
{{ if .Values.prometheus.alertmanager.ingress.enabled -}}
From outside the cluster, the alertmanager URL(s) are:

{{- range .Values.prometheus.alertmanager.ingress.hosts }}
    http://{{ . }}
{{- end }}
{{- else }}
Get the Prometheus Alertmanager URL by running these commands in the same shell:

{{- if contains "NodePort" .Values.prometheus.alertmanager.service.type }}

    export NODE_PORT=$(kubectl get --namespace {{ template "monitor.prometheus.namespace" . }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ template "monitor.prometheus.alertmanager.fullname" . }})
    export NODE_IP=$(kubectl get nodes --namespace {{ template "monitor.prometheus.namespace" . }} -o jsonpath="{.items[0].status.addresses[0].address}")
    echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.prometheus.alertmanager.service.type }}

    NOTE: It may take a few minutes for the LoadBalancer IP to be available.
          You can watch the status of by running 'kubectl get svc --namespace {{ template "monitor.prometheus.namespace" . }} -w {{ template "monitor.prometheus.alertmanager.fullname" . }}'

    export SERVICE_IP=$(kubectl get svc --namespace {{ template "monitor.prometheus.namespace" . }} {{ template "monitor.prometheus.alertmanager.fullname" . }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo http://$SERVICE_IP:{{ .Values.prometheus.alertmanager.service.servicePort }}
{{- else if contains "ClusterIP"  .Values.prometheus.alertmanager.service.type }}

    export POD_NAME=$(kubectl get pods --namespace {{ template "monitor.prometheus.namespace" . }} -l "app=prometheus,component={{ .Values.prometheus.alertmanager.name }}" -o jsonpath="{.items[0].metadata.name}")
    kubectl --namespace {{ template "monitor.prometheus.namespace" . }} port-forward $POD_NAME 9093
{{- end }}
{{- end }}

{{- if .Values.prometheus.alertmanager.persistentVolume.enabled }}
{{- else }}

#################################################################################
######   WARNING: Persistence is disabled!!! You will lose your data when   #####
######            the Prometheus AlertManager pod is terminated.            #####
#################################################################################

{{- end }}
{{- end }}

{{ template "_divider" }}
{{ if .Values.grafana.enabled }}
The Grafana Server can be accessed via port {{ .Values.grafana.service.port }} on the following DNS name from within your cluster:

    {{ template "monitor.grafana.fullname" . }}.{{ template "monitor.grafana.namespace" . }}.svc.cluster.local
{{ if .Values.grafana.ingress.enabled -}}
If you bind Grafana Server to {{ .Values.grafana.service.port }}, please update values in values.yaml and reinstall:
   ```
   securityContext:
     runAsUser: 0
     runAsGroup: 0
     fsGroup: 0

   command:
   - "setcap"
   - "'cap_net_bind_service=+ep'"
   - "/usr/sbin/grafana-server &&"
   - "sh"
   - "/run.sh"
   ```
Details refer to https://grafana.com/docs/installation/configuration/#http-port.
Or Grafana Server would always crash.

From outside the cluster, the Grafana Server URL(s) are:

{{- range .Values.grafana.ingress.hosts }}
    http://{{ . }}
{{- end }}
{{- else }}
Get the Grafana Server URL by running these commands in the same shell:

{{- if contains "NodePort" .Values.grafana.service.type }}

    export NODE_PORT=$(kubectl get --namespace {{ template "monitor.grafana.namespace" . }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ template "monitor.grafana.fullname" . }})
    export NODE_IP=$(kubectl get nodes --namespace {{ template "monitor.grafana.namespace" . }} -o jsonpath="{.items[0].status.addresses[0].address}")
    echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.grafana.service.type }}

    NOTE: It may take a few minutes for the LoadBalancer IP to be available.
          You can watch the status of by running 'kubectl get svc --namespace {{ template "monitor.grafana.namespace" . }} -w {{ template "monitor.grafana.fullname" . }}'

    export SERVICE_IP=$(kubectl get svc --namespace {{ template "monitor.grafana.namespace" . }} {{ template "monitor.grafana.fullname" . }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo http://$SERVICE_IP:{{ .Values.grafana.service.port }}
{{- else if contains "ClusterIP"  .Values.grafana.service.type }}

    export POD_NAME=$(kubectl get pods --namespace {{ template "monitor.grafana.namespace" . }} -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")
    kubectl --namespace {{ template "monitor.grafana.namespace" . }} port-forward $POD_NAME 3000
{{- end }}
{{- end }}

Get your '{{ .Values.grafana.adminUser }}' user password by running:

   kubectl get secret --namespace {{ template "monitor.grafana.namespace" . }} {{ template "monitor.grafana.fullname" . }} -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

Login with the password and the username: {{ .Values.grafana.adminUser }}
{{- if .Values.grafana.persistence.enabled }}
{{- else }}

#################################################################################
######   WARNING: Persistence is disabled!!! You will lose your data when   #####
######            the Grafana pod is terminated.                            #####
#################################################################################

{{- end }}
{{- end }}
