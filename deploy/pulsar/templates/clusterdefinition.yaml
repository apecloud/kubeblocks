apiVersion: apps.kubeblocks.io/v1alpha1
kind: ClusterDefinition
metadata:
  name: pulsar
  labels:
    {{- include "pulsar.labels" . | nindent 4 }}
spec:
  type: pulsar
  connectionCredential:
    username: "admin"
    admin-password: "$(RANDOM_PASSWD)"
    httpEndpoint: "http://$(SVC_FQDN):$(SVC_PORT_http)"
    pulsarEndpoint: "pulsar://$(SVC_FQDN):$(SVC_PORT_pulsar)"
  componentDefs:
    - name: proxy
      workloadType: Stateful
      characterType: pulsar-proxy
      statefulSpec:
        updateStrategy: BestEffortParallel
      componentDefRef:
      - componentDefName: broker
        componentRefEnv:
        - name: brokerSVC
          valueFrom:
            type: ServiceRef
      # TODO: support monitor
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9141
      logConfigs:
      # TODO: refer to broker configuration
      configSpecs:
      {{- if .Values.proxy.configuration }}
        - name: proxy-config
          templateRef: proxy-tpl
          namespace: {{ .Release.Namespace }}
          volumeName: config
      {{- end }}
      service:
        ports:
        - name: pulsar
          port: 6650
          protocol: TCP
          targetPort: 6650
        - name: http
          port: 8080
          protocol: TCP
          targetPort: 8080
      podSpec:
        securityContext:
          runAsNonRoot: true
          runAsUser: 10000
          fsGroup: 0
          runAsGroup: 0
        initContainers:
          - name: check-broker
            args:
            - set -e; while [ "$(curl -s -o /dev/null -w '%{http_code}' ${brokerSVC}:8080/status.html)"
                  -ne "200" ]; do echo "pulsar cluster isn't initialized yet..."; sleep 3;
              done
            command:
              - sh
              - -c
        containers:
          - name: proxy
            securityContext:
              allowPrivilegeEscalation: false
              runAsNonRoot: true
              runAsUser: 10000
              capabilities:
                drop:
                - ALL
              privileged: false
              runAsGroup: 0
            args:
            - bin/apply-config-from-env.py conf/proxy.conf && echo 'OK' > status && exec bin/pulsar proxy
            command:
              - sh
              - -c
            env:
            - name: brokerWebServiceURL
              value: http://$(brokerSVC):8080
            - name: brokerServiceURL
              value: pulsar://$(brokerSVC):6650
            - name: clusterName
              value: $(KB_NAMESPACE)-$(KB_CLUSTER_COMP_NAME)
            - name: webServicePort
              value: "8080"
            envFrom:
              - configMapRef:
                  name: proxy-test-config
            ports:
            - containerPort: 6650
              name: pulsar
              protocol: TCP
            - containerPort: 6651
              name: pulsarssl
              protocol: TCP
            - containerPort: 8443
              name: https
              protocol: TCP
            - containerPort: 8080
              name: http
              protocol: TCP
            livenessProbe:
              failureThreshold: 3
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            readinessProbe:
              failureThreshold: 3
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            startupProbe:
              failureThreshold: 20
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
    - name: broker
      workloadType: Stateful
      characterType: pulsar-broker
      statefulSpec:
        updateStrategy: BestEffortParallel
      componentDefRef:
      - componentDefName: zookeeper
        componentRefEnv:
        - name: zookeeperSVC
          valueFrom:
            type: ServiceRef
      # TODO: support monitor
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9141
      logConfigs:
      # TODO: refer to broker configuration
      configSpecs:
        - name: broker-interceptors
          templateRef: broker-interceptors-tpl
          namespace: {{ .Release.Namespace }}
          volumeName: interceptors
      {{- if .Values.broker.configuration }}
        - name: broker-tpl
          templateRef: broker-tpl
          namespace: {{ .Release.Namespace }}
          volumeName: config
      {{- end }}
      service:
        ports:
        - name: tcp-pulsar
          port: 6650
          targetPort: 6650
        - name: http
          port: 8080
          targetPort: 8080
      podSpec:
        securityContext:
          runAsNonRoot: true
          runAsUser: 10000
          fsGroup: 0
          runAsGroup: 0
        initContainers:
          - name: init-broker-cluster
            args:
            - |2-
              set -x
              echo "INFO: wait for zookeeper ready..."
              until bin/pulsar zookeeper-shell -server ${zookeeperServers} --run-once "ls /"; do
                sleep 3;
              done;
              idx=${KB_POD_NAME##*-}
              if [ $idx -ne 0 ]; then
                # if not the first pod, do it
                until bin/bookkeeper org.apache.zookeeper.ZooKeeperMain -server ${zookeeperServers} get /admin/clusters/${clusterName}; do
                  echo "INFO: wait for init the meta cluster..."
                  sleep 3;
                done
                echo "INFO: cluster already initialized" && exit 0
              fi
              # if the pod is the first pod, do it
              if bin/bookkeeper org.apache.zookeeper.ZooKeeperMain -server ${zookeeperServers} get /admin/clusters/${clusterName}; then
                echo "INFO: cluster already initialized" && exit 0
              fi
              echo "INFO: init cluster metadata for cluster: ${clusterName}"
              bin/pulsar initialize-cluster-metadata \
              --cluster ${clusterName} \
              --zookeeper ${zookeeperServers} \
              --configuration-store ${zookeeperServers} \
              --web-service-url ${webServiceUrl}
              # --web-service-url-tls https://pulsar-mini-broker.pulsar.svc.cluster.local:8443/ \
              # --broker-service-url ${brokerServiceUrl} \
              # --broker-service-url-tls pulsar+ssl://pulsar-mini-broker.pulsar.svc.cluster.local:6651/

              (curl -sf -XPOST http://127.0.0.1:15020/quitquitquit || true) && exit 0
            command:
              - sh
              - -c
            env:
            - name: brokerServiceUrl
              value: pulsar://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:6650
            - name: clusterName
              value: $(KB_NAMESPACE)-$(KB_CLUSTER_COMP_NAME)
            - name: webServiceUrl
              value: http://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:8080
            - name: zookeeperServers
              value: $(zookeeperSVC):2181
            - name: configurationStoreServers
              value: $(zookeeperSVC):2181
            envFrom:
            - configMapRef:
                name: broker-test-config
          - name: init-sysctl
            args:
            - "sysctl -w net.ipv4.tcp_keepalive_time=1 &&\n\t\t\tsysctl -w net.ipv4.tcp_keepalive_intvl=11
               &&\n\t\t\tsysctl -w net.ipv4.tcp_keepalive_probes=3"
            command:
            - /bin/sh
            - -c
            securityContext:
              privileged: true
              runAsNonRoot: false
              runAsUser: 0
        containers:
          - name: broker
            securityContext:
              allowPrivilegeEscalation: false
              runAsNonRoot: true
              runAsUser: 10000
              capabilities:
                drop:
                - ALL
              privileged: false
              runAsGroup: 0
            args:
            - bin/apply-config-from-env.py conf/broker.conf && bin/apply-config-from-env.py
                conf/client.conf && echo 'OK' > status;exec bin/pulsar broker
            command:
              - sh
              - -c
            resources:
              requests:
                cpu: 200m
                memory: 512Mi
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: PULSAR_PREFIX_brokerServicePort
              value: "6650"
            - name: PULSAR_PREFIX_internalListenerName
              value: cluster
            - name: PULSAR_PREFIX_advertisedListeners
              value: cluster:pulsar://$(POD_NAME).pulsar1-broker-headless.pulsar.svc.cluster.local:6650
            - name: PULSAR_PREFIX_bindAddresses
            - name: brokerServiceUrl
              value: pulsar://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:6650
            - name: clusterName
              value: $(KB_NAMESPACE)-$(KB_CLUSTER_COMP_NAME)
            - name: webServiceUrl
              value: http://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:8080
            - name: zookeeperServers
              value: $(zookeeperSVC):2181
            - name: configurationStoreServers
              value: $(zookeeperSVC):2181
            envFrom:
              - configMapRef:
                 # TODO: replace it when kb supports inject configMap
                  name: broker-test-config
              # TODO: using componentDefRef to inject zookeeper or keeper env
            ports:
              - containerPort: 6650
                name: tcp-pulsar
                protocol: TCP
              - containerPort: 8080
                name: http
                protocol: TCP
            livenessProbe:
              failureThreshold: 30
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            readinessProbe:
              failureThreshold: 3
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            startupProbe:
              failureThreshold: 30
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            volumeMounts:
            - name: interceptors
              mountPath: /pulsar/plugin_configs/interceptors
              readOnly: true
           #   - name: conf
           #     mountPath: /pulsar/conf
    - name: bookies
      workloadType: Stateful
      characterType: bookies
      statefulSpec:
        updateStrategy: BestEffortParallel
      configSpecs:
        - name: pulsar-bookies-config
          templateRef: pulsar-bookies-config
          namespace: {{ .Release.Namespace }}
          volumeName: pulsar-bookies-config
      podSpec:
        initContainers:
          - name: init-bookies
            command:
              - bash
              - -c
            args:
            - |
              echo "waiting zookeeper ready..."
              zkDomain="${zkServers%%:*}"
              until nslookup $zkDomain; do
                sleep 3;
              done;
              echo "zk is ready, start to config bookkeeper..."
              bin/apply-config-from-env.py conf/bookkeeper.conf;
              if bin/bookkeeper shell whatisinstanceid; then
                echo "bookkeeper cluster already initialized";
              else
                echo "bookkeeper init new cluster."
                bin/bookkeeper shell initnewcluster;
              fi
              echo "verify bookkeeper cluster id"
              bin/apply-config-from-env.py conf/bookkeeper.conf;until bin/bookkeeper shell whatisinstanceid; do
                sleep 3;
              done; bin/bookkeeper shell bookieformat -nonInteractive -force -deleteCookie || true
            envFrom:
              - configMapRef:
                  name: pulsar-bookies-pulsar-bookies-config
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
        containers:
          - name: bookies
            command:
              - bash
              - -c
            args:
            - |
              bin/apply-config-from-env.py conf/bookkeeper.conf;
              OPTS="${OPTS} -Dlog4j2.formatMsgNoLookups=true" exec bin/pulsar bookie;
            envFrom:
              - configMapRef:
                  ## name: bookies-bk-config
                  name: pulsar-bookies-pulsar-bookies-config
            livenessProbe:
              failureThreshold: 60
              httpGet:
                path: /api/v1/bookie/state
                port: 8000
                scheme: HTTP
              initialDelaySeconds: 10
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            ports:
              - containerPort: 8000
                name: http
                protocol: TCP
              - containerPort: 3181
                name: bookie
                protocol: TCP
            readinessProbe:
              failureThreshold: 60
              httpGet:
                path: /api/v1/bookie/is_ready
                port: 8000
                scheme: HTTP
              initialDelaySeconds: 10
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            resources:
              requests:
                cpu: 200m
                memory: 512Mi
            securityContext:
              runAsUser: 0
              runAsGroup: 10000
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
              - mountPath: /pulsar/data/bookkeeper/journal
                name: journal
              - mountPath: /pulsar/data/bookkeeper/ledgers
                name: ledgers
    - name: zookeeper
      workloadType: Stateful
      characterType: zookeeper
      statefulSpec:
        updateStrategy: BestEffortParallel
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9141
      logConfigs:
        {{- range $name,$pattern := .Values.zookeeper.logConfigs }}
        - name: {{ $name }}
          filePathPattern: {{ $pattern }}
        {{- end }}
      configSpecs:
        - name: pulsar-zookeeper-config
          templateRef: pulsar-zookeeper-config
          namespace: {{ .Release.Namespace }}
          volumeName: pulsar-zookeeper-config
      service:
        ports:
          - name: client
            port: 2181
            targetPort: client
          - name: metrics
            port: 9141
            targetPort: metrics
      podSpec:
        securityContext:
          fsGroup: 0
          runAsGroup: 0
          runAsNonRoot: true
          runAsUser: 10000
        containers:
          - name: zookeeper
            command:
              - bash
              - -c
            args:
              - |-
                bin/apply-config-from-env.py conf/zookeeper.conf;
                bin/generate-zookeeper-config.sh conf/zookeeper.conf; exec bin/pulsar zookeeper;
            env:
              - name: EXTERNAL_PROVIDED_SERVERS
                value: "false"
              - name: OPTS
                value: "-Dlog4j2.formatMsgNoLookups=true -XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
            envFrom:
              - configMapRef:
                  ## name: zookeepers-zk-config
                  name: pulsar-zookeeper-pulsar-zookeeper-config
            ports:
              - containerPort: 2181
                name: client
                protocol: TCP
              - containerPort: 2888
                name: tcp-quorum
                protocol: TCP
              - containerPort: 3888
                name: tcp-election
                protocol: TCP
              - containerPort: 9141
                name: metrics
                protocol: TCP
              - containerPort: 9990
                name: http-admin
                protocol: TCP
            livenessProbe:
              exec:
                command:
                  - timeout
                  - "30"
                  - bash
                  - -c
                  - echo ruok | nc -q 1 localhost 2181 | grep imok
              failureThreshold: 10
              initialDelaySeconds: 20
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 30
            readinessProbe:
              exec:
                command:
                  - timeout
                  - "30"
                  - bash
                  - -c
                  - echo ruok | nc -q 1 localhost 2181 | grep imok
              failureThreshold: 10
              initialDelaySeconds: 20
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 30
            resources:
              requests:
                cpu: 50m
                memory: 256Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                  - ALL
              privileged: false
              runAsGroup: 0
              runAsNonRoot: true
              runAsUser: 10000
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
              - mountPath: /pulsar/data
                name: data
              - mountPath: /pulsar/data-log
                name: data-log