apiVersion: apps.kubeblocks.io/v1alpha1
kind: ClusterDefinition
metadata:
  name: pulsar
  labels:
    {{- include "pulsar.labels" . | nindent 4 }}
    {{- if .Values.commonLabels }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonLabels "context" $ ) | nindent 4 }}
    {{- end }}
  {{- if .Values.commonAnnotations }}
  annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
  {{- end }}
spec:
  type: pulsar
  connectionCredential:
    username: "admin"
    admin-password: "$(RANDOM_PASSWD)"
    endpoint: "http://$(SVC_FQDN):$(SVC_PORT_http)"
    tcpEndpoint: "$(SVC_FQDN):$(SVC_PORT_tcp)"
    mysqlEndpoint: "$(SVC_FQDN):$(SVC_PORT_tcp-mysql)"
    pgEndpoint: "$(SVC_FQDN):$(SVC_PORT_tcp-postgresql)"
  componentDefs:
    - name: bookies-bk
      workloadType: Stateful
      characterType: bookies
      statefulSpec:
        updateStrategy: BestEffortParallel
      configSpecs:
        - name: bookies-bk-config
          templateRef: bookies-bk-config
          namespace: {{ .Release.Namespace }}
          volumeName: bookies-bk-config
      podSpec:
        initContainers:
          - args:
            - |
              echo "waiting zookeeper ready..."
              zkDomain="${zkServers%%:*}"
              until nslookup $zkDomain; do
                sleep 3;
              done;
              echo "zk is ready, start to config bookkeeper..."
              bin/apply-config-from-env.py conf/bookkeeper.conf;
              if bin/bookkeeper shell whatisinstanceid; then
                echo "bookkeeper cluster already initialized";
              else
                echo "bookkeeper init new cluster."
                bin/bookkeeper shell initnewcluster;
              fi
              echo "verify bookkeeper cluster id"
              bin/apply-config-from-env.py conf/bookkeeper.conf;until bin/bookkeeper shell whatisinstanceid; do
                sleep 3;
              done; bin/bookkeeper shell bookieformat -nonInteractive -force -deleteCookie || true
            command:
              - sh
              - -c
            envFrom:
              - configMapRef:
                  name: pulsar-pulsar-cluster-bookies-bookies-bk-config
            image: apachepulsar/pulsar:2.11.1
            imagePullPolicy: IfNotPresent
            name: pulsar-bookkeeper-verify-clusterid
            resources: { }
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
        containers:
          - args:
            - |
              bin/apply-config-from-env.py conf/bookkeeper.conf;
              OPTS="${OPTS} -Dlog4j2.formatMsgNoLookups=true" exec bin/pulsar bookie;
            command:
              - bash
              - -c
            envFrom:
              - configMapRef:
                  ## name: bookies-bk-config
                  name: pulsar-pulsar-cluster-bookies-bookies-bk-config
            ## image: streamnative/sn-platform-slim:2.10.3.4
            image: apachepulsar/pulsar:2.11.1
            imagePullPolicy: IfNotPresent
            livenessProbe:
              failureThreshold: 60
              httpGet:
                path: /api/v1/bookie/state
                port: 8000
                scheme: HTTP
              initialDelaySeconds: 10
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            name: bookie
            ports:
              - containerPort: 8000
                name: http
                protocol: TCP
              - containerPort: 3181
                name: bookie
                protocol: TCP
            readinessProbe:
              failureThreshold: 60
              httpGet:
                path: /api/v1/bookie/is_ready
                port: 8000
                scheme: HTTP
              initialDelaySeconds: 10
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            resources:
              requests:
                cpu: 200m
                memory: 512Mi
            securityContext:
              runAsUser: 0
              runAsGroup: 10000
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
              - mountPath: /pulsar/data/bookkeeper/journal-0
                name: journal-0
              - mountPath: /pulsar/data/bookkeeper/ledgers-0
                name: ledgers-0
    - name: zookeeper
      workloadType: Stateful
      characterType: zookeeper
      statefulSpec:
        updateStrategy: BestEffortParallel
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9141
      logConfigs:
        {{- range $name,$pattern := .Values.zookeeper.logConfigs }}
        - name: {{ $name }}
          filePathPattern: {{ $pattern }}
        {{- end }}
      configSpecs:
        - name: zookeepers-zk-config
          templateRef: zookeepers-zk-config
          namespace: {{ .Release.Namespace }}
          volumeName: zookeepers-zk-config
      service:
        ports:
          - name: client
            port: 2181
            targetPort: client
          - name: metrics
            port: 9141
            targetPort: metrics
      podSpec:
        securityContext:
          fsGroup: 0
          runAsGroup: 0
          runAsNonRoot: true
          runAsUser: 10000
        containers:
          - command:
              - bash
              - -c
            args:
              - |-
                bin/apply-config-from-env.py conf/zookeeper.conf;
                bin/generate-zookeeper-config.sh conf/zookeeper.conf; exec bin/pulsar zookeeper;
            env:
              - name: EXTERNAL_PROVIDED_SERVERS
                value: "false"
              - name: OPTS
                value: "-Dlog4j2.formatMsgNoLookups=true -XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
            envFrom:
              - configMapRef:
                  ## name: zookeepers-zk-config
                  name: pulsar-pulsar-cluster-zookeeper-zookeepers-zk-config
            image: apachepulsar/pulsar:2.11.1
            imagePullPolicy: IfNotPresent
            lifecycle: {}
            livenessProbe:
              exec:
                command:
                  - timeout
                  - "30"
                  - bash
                  - -c
                  - echo ruok | nc -q 1 localhost 2181 | grep imok
              failureThreshold: 10
              initialDelaySeconds: 20
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 30
            name: zookeeper
            ports:
              - containerPort: 2181
                name: client
                protocol: TCP
              - containerPort: 2888
                name: tcp-quorum
                protocol: TCP
              - containerPort: 3888
                name: tcp-election
                protocol: TCP
              - containerPort: 9141
                name: metrics
                protocol: TCP
              - containerPort: 9990
                name: http-admin
                protocol: TCP
            readinessProbe:
              exec:
                command:
                  - timeout
                  - "30"
                  - bash
                  - -c
                  - echo ruok | nc -q 1 localhost 2181 | grep imok
              failureThreshold: 10
              initialDelaySeconds: 20
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 30
            resources:
              requests:
                cpu: 50m
                memory: 256Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                  - ALL
              privileged: false
              runAsGroup: 0
              runAsNonRoot: true
              runAsUser: 10000
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
              - mountPath: /pulsar/data
                name: data
              - mountPath: /pulsar/data-log
                name: data-log
    - name: broker
      workloadType: Stateful
      characterType: broker
      componentDefRef:
      - componentDefName: zookeeper
        componentRefEnv:
        - name: zookeeperSVC
          valueFrom:
            type: ServiceRef
      # TODO: support monitor
      monitor:
        builtIn: false
        exporterConfig:
          scrapePath: /metrics
          scrapePort: 9141
      logConfigs:
      # TODO: refer to broker configuration
      configSpecs:
        - name: broker-interceptors
          templateRef: broker-interceptors-tpl
          namespace: {{ .Release.Namespace }}
          volumeName: interceptors
      {{- if .Values.broker.configuration }}
        - name: broker-tpl
          templateRef: broker-tpl
          namespace: {{ .Release.Namespace }}
          volumeName: config
      {{- end }}
      service:
        ports:
        - name: tcp-pulsar
          port: 6650
          targetPort: 6650
        - name: http
          port: 8080
          targetPort: 8080
      podSpec:
        securityContext:
          runAsNonRoot: true
          runAsUser: 10000
          fsGroup: 0
          runAsGroup: 0
        initContainers:
          - name: init-broker-cluster
            args:
            - |2-
              set -x
              # wait zookeeper ready
              echo "INFO: wait for zookeeper ready..."
              until bin/pulsar zookeeper-shell -server ${zookeeperServers} --run-once "ls /"; do
                sleep 3;
              done;
              # wait bookkeeper ready
              # bin/apply-config-from-env.py conf/bookkeeper.conf;
              # echo "INFO: wait for bookkeeper ready..."
              # until bin/bookkeeper shell whatisinstanceid; do
              #  sleep 3;
              # done;
              idx=${KB_POD_NAME##*-}
              if [ $idx -ne 0 ]; then
                exit 0
              fi
              if bin/bookkeeper org.apache.zookeeper.ZooKeeperMain -server ${zookeeperServers} get /admin/clusters/${clusterName}; then
                  echo "INFO: cluster already initialized" && exit 0
              fi
              echo "INFO: init cluster metadata for cluster: ${clusterName}"
              bin/pulsar initialize-cluster-metadata \
                --cluster ${clusterName} \
                --zookeeper ${zookeeperServers} \
                --configuration-store ${zookeeperServers} \
                --web-service-url ${webServiceUrl}
                # --web-service-url-tls https://pulsar-mini-broker.pulsar.svc.cluster.local:8443/ \
                # --broker-service-url ${brokerServiceUrl} \
                # --broker-service-url-tls pulsar+ssl://pulsar-mini-broker.pulsar.svc.cluster.local:6651/

              bin/pulsar initialize-namespace -cs zookeepers-zk:2181 \
                --cluster $clusterName sn/system && (curl -sf -XPOST http://127.0.0.1:15020/quitquitquit || true)
            command:
              - sh
              - -c
            env:
            - name: brokerServiceUrl
              value: pulsar://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:6650
            - name: clusterName
              value: $(KB_NAMESPACE)-$(KB_CLUSTER_NAME)
            - name: webServiceUrl
              value: http://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:8080
            - name: zookeeperServers
              value: $(zookeeperSVC):2181
            - name: configurationStoreServers
              value: $(zookeeperSVC):2181
            envFrom:
            - configMapRef:
                name: broker-test-config
          - name: init-sysctl
            args:
            - "sysctl -w net.ipv4.tcp_keepalive_time=1 &&\n\t\t\tsysctl -w net.ipv4.tcp_keepalive_intvl=11
               &&\n\t\t\tsysctl -w net.ipv4.tcp_keepalive_probes=3"
            command:
            - /bin/sh
            - -c
            securityContext:
              privileged: true
              runAsNonRoot: false
              runAsUser: 0
        containers:
          - name: broker
            securityContext:
              allowPrivilegeEscalation: false
              runAsNonRoot: true
              runAsUser: 10000
              capabilities:
                drop:
                - ALL
              privileged: false
              runAsGroup: 0
            args:
            - bin/apply-config-from-env.py conf/broker.conf && bin/apply-config-from-env.py
                conf/client.conf && echo 'OK' > status;exec bin/pulsar broker
            command:
              - sh
              - -c
            resources:
              requests:
                cpu: 200m
                memory: 512Mi
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: PULSAR_PREFIX_brokerServicePort
              value: "6650"
            - name: PULSAR_PREFIX_internalListenerName
              value: cluster
            - name: PULSAR_PREFIX_advertisedListeners
              value: cluster:pulsar://$(POD_NAME).pulsar1-broker-headless.pulsar.svc.cluster.local:6650
            - name: PULSAR_PREFIX_bindAddresses
            - name: brokerServiceUrl
              value: pulsar://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:6650
            - name: clusterName
              value: $(KB_NAMESPACE)-$(KB_CLUSTER_NAME)
            - name: webServiceUrl
              value: http://$(KB_CLUSTER_COMP_NAME).$(KB_NAMESPACE).svc.cluster.local:8080
            - name: zookeeperServers
              value: $(zookeeperSVC):2181
            - name: configurationStoreServers
              value: $(zookeeperSVC):2181
            envFrom:
              - configMapRef:
                 # TODO: replace it when kb supports inject configMap
                  name: broker-test-config
              # TODO: using componentDefRef to inject zookeeper or keeper env
            ports:
              - containerPort: 6650
                name: tcp-pulsar
                protocol: TCP
              - containerPort: 8080
                name: http
                protocol: TCP
            livenessProbe:
              failureThreshold: 30
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            readinessProbe:
              failureThreshold: 3
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            startupProbe:
              failureThreshold: 30
              httpGet:
                path: /status.html
                port: http
                scheme: HTTP
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 100
            volumeMounts:
            - name: interceptors
              mountPath: /pulsar/plugin_configs/interceptors
              readOnly: true
           #   - name: conf
           #     mountPath: /pulsar/conf