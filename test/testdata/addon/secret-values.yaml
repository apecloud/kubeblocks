apiVersion: v1
kind: Secret
metadata:
  name: prometheus-chart-kubeblocks-values
  namespace: default
stringData:
  values-kubeblocks-override-2.yaml: |-
    alertmanager:
      ## If false, alertmanager will not be installed
      ##
      enabled: true

      ## alertmanager container image
      ##
      image:
        repository: docker.io/apecloud/alertmanager
        tag: v0.24.0

      ## Node tolerations for alertmanager scheduling to nodes with taints
      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
      ##
      tolerations: [ ]
        # - key: "key"
        #   operator: "Equal|Exists"
        #   value: "value"
        #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

      persistentVolume:
        ## If true, alertmanager will create/use a Persistent Volume Claim
        ## If false, use emptyDir
        ##
        enabled: true

        ## alertmanager data Persistent Volume size
        ##
        size: 1Gi

        ## alertmanager data Persistent Volume Storage Class
        ## If defined, storageClassName: <storageClass>
        ## If set to "-", storageClassName: "", which disables dynamic provisioning
        ## If undefined (the default) or set to null, no storageClassName spec is
        ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
        ##   GKE, AWS & OpenStack)
        ##
        # storageClass: "-"

      ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)
      ##
      replicaCount: 1

      statefulSet:
        ## If true, use a statefulset instead of a deployment for pod management.
        ## This allows to scale replicas to more than 1 pod
        ##
        enabled: true

        ## Alertmanager headless service to use for the statefulset
        ##
        headless:
          ## Enabling peer mesh service end points for enabling the HA alert manager
          ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md
          enableMeshPeer: true

      ## alertmanager resource requests and limits
      ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
      ##
      resources: {}
        # limits:
        #   cpu: 10m
        #   memory: 32Mi
        # requests:
        #   cpu: 10m
      #   memory: 32Mi

      ## Security context to be added to alertmanager pods
      ##
      securityContext:
        runAsUser: 0
        runAsNonRoot: false
        runAsGroup: 65534
        fsGroup: 65534

      containerSecurityContext:
        allowPrivilegeEscalation: false

    kubeStateMetrics:
      ## If false, kube-state-metrics sub-chart will not be installed
      ##
      enabled: false

    nodeExporter:
      ## If false, node-exporter will not be installed
      ##
      enabled: false

      ## node-exporter container image
      ##
      image:
        repository: docker.io/apecloud/node-exporter
        tag: v1.3.1

    server:
      ## Prometheus server container name
      ##
      enabled: true

      ## Prometheus server container image
      ##
      image:
        repository: docker.io/apecloud/prometheus
        tag: v2.39.1

      global:
        ## How frequently to scrape targets by default
        ##
        scrape_interval: 15s
        ## How long until a scrape request times out
        ##
        scrape_timeout: 10s
        ## How frequently to evaluate rules
        ##
        evaluation_interval: 15s

      ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write
      ##
      remoteWrite: []

      ## Prefix used to register routes, overriding externalUrl route.
      ## Useful for proxies that rewrite URLs.
      ##
      routePrefix: /

      ## Node tolerations for server scheduling to nodes with taints
      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
      ##
      tolerations: [ ]
        # - key: "key"
        #   operator: "Equal|Exists"
        #   value: "value"
      #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

      persistentVolume:
        ## If true, Prometheus server will create/use a Persistent Volume Claim
        ## If false, use emptyDir
        ##
        enabled: true

        ## Prometheus server data Persistent Volume size
        ##
        size: 8Gi

        ## Prometheus server data Persistent Volume Storage Class
        ## If defined, storageClassName: <storageClass>
        ## If set to "-", storageClassName: "", which disables dynamic provisioning
        ## If undefined (the default) or set to null, no storageClassName spec is
        ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
        ##   GKE, AWS & OpenStack)
        ##
        # storageClass: "-"

      ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)
      ##
      replicaCount: 1

      statefulSet:
        ## If true, use a statefulset instead of a deployment for pod management.
        ## This allows to scale replicas to more than 1 pod
        ##
        enabled: true

      ## Prometheus server resource requests and limits
      ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
      ##
      resources: {}
        # limits:
        #   cpu: 500m
        #   memory: 512Mi
        # requests:
        #   cpu: 500m
      #   memory: 512Mi

      ## Prometheus' data retention period (default if not specified is 15 days)
      ##
      retention: "3d"

      ## Security context to be added to server pods
      ##
      securityContext:
        runAsUser: 0
        runAsNonRoot: false
        runAsGroup: 65534
        fsGroup: 65534

      containerSecurityContext:
        allowPrivilegeEscalation: false

    ## Sample prometheus rules/alerts
    ## NOTE: Please review these carefully as thresholds and behavior may not meet
    ##       your SLOs or labels.
    ##
    ruleFiles:
      cadvisor_alert_rules.yml: |
        groups:
          - name: GoogleCadvisor
            rules:
              - alert: ContainerKilled
                expr: 'time() - container_last_seen{container!="",container!="POD"} > 60'
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "Container killed (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "A container has disappeared\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerCpuUsageWarning
                expr: 'sum(rate(container_cpu_usage_seconds_total{container!="",container!="POD"}[2m])) BY (instance,pod,container) * 100 > 70'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "Container CPU usage is high (> 70%) (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "Container CPU usage is above 70%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerCpuUsageCritical
                expr: 'sum(rate(container_cpu_usage_seconds_total{container!="",container!="POD"}[2m])) BY (instance,pod,container) * 100 > 90'
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "Container CPU usage is very high (> 90%) (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "Container CPU usage is above 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerMemoryUsage
                expr: 'sum(container_memory_working_set_bytes{container!="",container!="POD"}) BY (instance,pod,container) / sum(container_spec_memory_limit_bytes{container!="",container!="POD"} > 0) BY (instance,pod,container) * 100 > 90'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "Container Memory usage is high (> 90%) (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "Container Memory usage is above 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerMemoryUsagePredict
                expr: 'sum(predict_linear(container_memory_working_set_bytes{container!="",container!="POD"}[15m], 30*60)) BY (instance,pod,container) - sum(container_spec_memory_limit_bytes{container!="",container!="POD"} > 0) BY (instance,pod,container) >= 0'
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: "Container Memory usage may exceed the limit 30 minutes later (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "Container Memory usage may exceed the limit 30 minutes later\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerVolumeUsage
                expr: 'sum(container_fs_usage_bytes) BY (instance,device) / sum(container_fs_limit_bytes) BY (instance,device) * 100 > 90'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "Device Volume usage is high (> 90%) (node: {{ $labels.instance }}, device: {{ $labels.device }})"
                  description: "Device Volume usage is above 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: ContainerHighCpuThrottleRate
                expr: 'rate(container_cpu_cfs_throttled_seconds_total{container!="",container!="POD"}[2m]) > 1'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "Container high throttle rate (node: {{ $labels.instance }}, pod: {{ $labels.pod }}, container: {{ $labels.container }})"
                  description: "Container is being throttled\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      mysql_alert_rules.yml: |
        groups:
          - name: MysqldExporter
            rules:
              - alert: MysqlDown
                expr: 'max_over_time(mysql_up[1m]) == 0'
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "MySQL is down (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "MySQL instance is down on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlRestarted
                expr: 'mysql_global_status_uptime < 60'
                for: 0m
                labels:
                  severity: info
                annotations:
                  summary: "MySQL restarted (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "MySQL has just been restarted, less than one minute ago on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlTooManyConnections
                expr: 'sum(max_over_time(mysql_global_status_threads_connected[1m]) / mysql_global_variables_max_connections) BY (namespace,app_kubernetes_io_instance,pod) * 100 > 80'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "MySQL too many connections (> 80%) (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "More than 80% of MySQL connections are in use on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlConnectionErrors
                expr: 'sum(increase(mysql_global_status_connection_errors_total[1m])) BY (namespace,app_kubernetes_io_instance,pod) > 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "MySQL connection errors (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "MySQL server has some connection errors on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlHighThreadsRunning
                expr: 'sum(max_over_time(mysql_global_status_threads_running[1m]) / mysql_global_variables_max_connections) BY (namespace,app_kubernetes_io_instance,pod) * 100 > 60'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "MySQL high threads running (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "More than 60% of MySQL connections are in running state on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlSlowQueries
                expr: 'sum(increase(mysql_global_status_slow_queries[1m])) BY (namespace,app_kubernetes_io_instance,pod) > 0'
                for: 2m
                labels:
                  severity: info
                annotations:
                  summary: "MySQL slow queries (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "MySQL server has some new slow query on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlInnodbLogWaits
                expr: 'sum(rate(mysql_global_status_innodb_log_waits[5m])) BY (namespace,app_kubernetes_io_instance,pod) > 10'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "MySQL InnoDB log waits (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "MySQL innodb log writes stalling on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: MysqlInnodbBufferPoolHits
                expr: 'sum(rate(mysql_global_status_innodb_buffer_pool_reads[5m]) / rate(mysql_global_status_innodb_buffer_pool_read_requests[5m])) BY (namespace,app_kubernetes_io_instance,pod) * 100 > 5'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "MySQL InnoDB high read requests rate hitting disk (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "High number of logical reads that InnoDB could not satisfy from the buffer pool, and had to read directly from disk on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      postgresql_alert_rules.yml: |
        groups:
          - name: PostgreSQLExporter
            rules:
              - alert: PostgreSQLDown
                expr: 'max_over_time(pg_up[1m]) == 0'
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "PostgreSQL is down (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL instance is down on {{ $labels.instance }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLExporterError
                expr: 'pg_exporter_last_scrape_error > 0'
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL exporter scrape error (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL exporter is showing errors. A query may be buggy in query.yaml\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTooManySlowQueries
                expr: |
                  max by(namespace,app_kubernetes_io_instance,pod,datname) (
                    max_over_time(pg_stat_activity_max_tx_duration{datname!~"template.*|postgres"}[2m])
                  ) > 60
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL database {{ $labels.datname }} high number of slow queries (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL high number of slow queries\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTooManyConnections
                expr: |
                  sum by (namespace,app_kubernetes_io_instance,pod) (pg_stat_activity_count{datname!~"template.*|postgres"})
                  > on(namespace,app_kubernetes_io_instance,pod)
                  (pg_settings_max_connections - pg_settings_superuser_reserved_connections) * 0.8
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL too many connections (> 80%) (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL instance has too many connections (> 80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLDeadLocks
                expr: 'increase(pg_stat_database_deadlocks{datname!~"template.*|postgres", datname!=""}[2m]) > 5'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL database {{ $labels.datname }} dead locks (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL has deadlocks\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLHighRollbackRate
                expr: |
                  rate(pg_stat_database_xact_rollback{datname!~"template.*|postgres", datname!=""}[2m])
                  /
                  rate(pg_stat_database_xact_commit{datname!~"template.*|postgres", datname!=""}[2m])
                  > 0.1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL database {{ $labels.datname }} high rollback rate (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Ratio of transactions being aborted compared to committed is > 2%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTooManyLocksAcquired
                expr: |
                  sum by (namespace,app_kubernetes_io_instance,pod) (pg_locks_count)
                  / on(namespace,app_kubernetes_io_instance,pod)
                  (pg_settings_max_locks_per_transaction * pg_settings_max_connections)
                  > 0.2
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL too many locks acquired (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Too many locks acquired on the database. If this alert happens frequently, we may need to increase the postgres setting max_locks_per_transaction.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLCacheHitRatio
                expr: |
                  avg by (namespace,app_kubernetes_io_instance,pod,datname) (
                    rate(pg_stat_database_blks_hit{datname!~"template.*|postgres", datname!=""}[2m])
                    /
                    (
                      rate(
                        pg_stat_database_blks_hit{datname!~"template.*|postgres", datname!=""}[2m]
                      )
                      +
                      rate(
                        pg_stat_database_blks_read{datname!~"template.*|postgres", datname!=""}[2m]
                      )
                    )
                  ) < 0.9
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL database {{ $labels.datname }} has low cache hit rate (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Low cache hit rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLMaxWriteBufferReached
                expr: 'rate(pg_stat_bgwriter_maxwritten_clean_total[2m]) > 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL write buffers reached max (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL background writer stops for max\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLHighWALFilesArchiveErrorRate
                expr: |
                  rate(pg_stat_archiver_failed_count[2m])
                  / (
                    rate(pg_stat_archiver_archived_count[2m]) + rate(pg_stat_archiver_failed_count[2m])
                  ) > 0.1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL high error rate in WAL files archiver (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "PostgreSQL high error rate in WAL files archiver\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTableNotAutoVacuumed
                expr: |
                  (pg_stat_user_tables_last_autovacuum > 0)
                  and
                  (time() - pg_stat_user_tables_last_autovacuum)
                  > 24 * 60 * 60 * 10
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL table {{ $labels.relname }} in database {{ $labels.datname }} not auto vacuumed (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Table {{ $labels.relname }} in database {{ $labels.datname }} has not been auto vacuumed for 10 days\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTableNotAutoAnalyzed
                expr: |
                  (pg_stat_user_tables_last_autoanalyze > 0)
                  and
                  (time() - pg_stat_user_tables_last_autoanalyze)
                  > 24 * 60 * 60 * 10
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL table {{ $labels.relname }} in database {{ $labels.datname }} not auto analyzed (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Table {{ $labels.relname }} in database {{ $labels.datname }} has not been auto analyzed for 10 days\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: PostgreSQLTableTooManyDeadTuples
                expr: |
                  (pg_stat_user_tables_n_dead_tup > 10000)
                  /
                  (pg_stat_user_tables_n_live_tup + pg_stat_user_tables_n_dead_tup)
                  >= 0.1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "PostgreSQL table {{ $labels.relname }} in database {{ $labels.datname }} has too many dead tuples (namespace: {{ $labels.namespace }}, cluster: {{ $labels.app_kubernetes_io_instance }}, instance: {{ $labels.pod }})"
                  description: "Table {{ $labels.relname }} in database {{ $labels.datname }} dead tuples is too large\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    serverFiles:
      prometheus.yml:
        rule_files:
          - /etc/config/recording_rules.yml
          - /etc/config/alerting_rules.yml
          - /etc/config/cadvisor_alert_rules.yml
          - /etc/config/mysql_alert_rules.yml
          - /etc/config/postgresql_alert_rules.yml

        scrape_configs:
          - job_name: prometheus
            static_configs:
              - targets:
                  - localhost:9090

          # Scrape config for API servers.
          #
          # Kubernetes exposes API servers as endpoints to the default/kubernetes
          # service so this uses `endpoints` role and uses relabelling to only keep
          # the endpoints associated with the default/kubernetes service using the
          # default named port `https`. This works for single API server deployments as
          # well as HA API server deployments.
          - job_name: 'kubernetes-apiservers'

            kubernetes_sd_configs:
              - role: endpoints

            # Default to scraping over https. If required, just disable this or change to
            # `http`.
            scheme: https

            # This TLS & bearer token file config is used to connect to the actual scrape
            # endpoints for cluster components. This is separate to discovery auth
            # configuration because discovery & scraping are two separate concerns in
            # Prometheus. The discovery auth config is automatic if Prometheus runs inside
            # the cluster. Otherwise, more config options have to be provided within the
            # <kubernetes_sd_config>.
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              # If your node certificates are self-signed or use a different CA to the
              # master CA, then disable certificate verification below. Note that
              # certificate verification is an integral part of a secure infrastructure
              # so this should only be disabled in a controlled environment. You can
              # disable certificate verification by uncommenting the line below.
              #
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

            # Keep only the default/kubernetes service endpoints for the https port. This
            # will add targets for each API server which Kubernetes adds an endpoint to
            # the default/kubernetes service.
            relabel_configs:
              - source_labels: [ __meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name ]
                action: keep
                regex: default;kubernetes;https

          - job_name: 'kubernetes-nodes'

            # Default to scraping over https. If required, just disable this or change to
            # `http`.
            scheme: https

            # This TLS & bearer token file config is used to connect to the actual scrape
            # endpoints for cluster components. This is separate to discovery auth
            # configuration because discovery & scraping are two separate concerns in
            # Prometheus. The discovery auth config is automatic if Prometheus runs inside
            # the cluster. Otherwise, more config options have to be provided within the
            # <kubernetes_sd_config>.
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              # If your node certificates are self-signed or use a different CA to the
              # master CA, then disable certificate verification below. Note that
              # certificate verification is an integral part of a secure infrastructure
              # so this should only be disabled in a controlled environment. You can
              # disable certificate verification by uncommenting the line below.
              #
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

            kubernetes_sd_configs:
              - role: node

            relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - target_label: __address__
                replacement: kubernetes.default.svc:443
              - source_labels: [ __meta_kubernetes_node_name ]
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/$1/proxy/metrics

          - job_name: 'kubernetes-nodes-cadvisor'

            # Default to scraping over https. If required, just disable this or change to
            # `http`.
            scheme: https

            # This TLS & bearer token file config is used to connect to the actual scrape
            # endpoints for cluster components. This is separate to discovery auth
            # configuration because discovery & scraping are two separate concerns in
            # Prometheus. The discovery auth config is automatic if Prometheus runs inside
            # the cluster. Otherwise, more config options have to be provided within the
            # <kubernetes_sd_config>.
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              # If your node certificates are self-signed or use a different CA to the
              # master CA, then disable certificate verification below. Note that
              # certificate verification is an integral part of a secure infrastructure
              # so this should only be disabled in a controlled environment. You can
              # disable certificate verification by uncommenting the line below.
              #
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

            kubernetes_sd_configs:
              - role: node

            # This configuration will work only on kubelet 1.7.3+
            # As the scrape endpoints for cAdvisor have changed
            # if you are using older version you need to change the replacement to
            # replacement: /api/v1/nodes/$1:4194/proxy/metrics
            # more info here https://github.com/coreos/prometheus-operator/issues/633
            relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - target_label: __address__
                replacement: kubernetes.default.svc:443
              - source_labels: [ __meta_kubernetes_node_name ]
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor

          # Example scrape config for pods
          #
          # The relabeling allows the actual pod scrape endpoint to be configured via the
          # following annotations:
          #
          # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`,
          # except if `prometheus.io/scrape-slow` is set to `true` as well.
          # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
          # to set this to `https` & most likely set the `tls_config` of the scrape config.
          # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
          # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
          - job_name: 'kubernetes-pods'
            honor_labels: true

            kubernetes_sd_configs:
              - role: pod

            relabel_configs:
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape ]
                action: keep
                regex: true
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow ]
                action: drop
                regex: true
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scheme ]
                action: replace
                regex: (https?)
                target_label: __scheme__
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_path ]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [ __address__, __meta_kubernetes_pod_annotation_prometheus_io_port ]
                action: replace
                regex: (.+?)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_controller_(.+)
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_statefulset_(.+)
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_cs_(.+)
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [ __meta_kubernetes_namespace ]
                action: replace
                target_label: namespace
              - source_labels: [ __meta_kubernetes_pod_name ]
                action: replace
                target_label: pod
              - source_labels: [ __meta_kubernetes_pod_phase ]
                regex: Pending|Succeeded|Failed|Completed
                action: drop

          # Example Scrape config for pods which should be scraped slower. An useful example
          # would be stackriver-exporter which queries an API on every scrape of the pod
          #
          # The relabeling allows the actual pod scrape endpoint to be configured via the
          # following annotations:
          #
          # * `prometheus.io/scrape-slow`: Only scrape pods that have a value of `true`
          # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
          # to set this to `https` & most likely set the `tls_config` of the scrape config.
          # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
          # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
          - job_name: 'kubernetes-pods-slow'
            honor_labels: true

            scrape_interval: 5m
            scrape_timeout: 30s

            kubernetes_sd_configs:
              - role: pod

            relabel_configs:
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow ]
                action: keep
                regex: true
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_scheme ]
                action: replace
                regex: (https?)
                target_label: __scheme__
              - source_labels: [ __meta_kubernetes_pod_annotation_prometheus_io_path ]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [ __address__, __meta_kubernetes_pod_annotation_prometheus_io_port ]
                action: replace
                regex: (.+?)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_controller_(.+)
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_statefulset_(.+)
              - action: labeldrop
                regex: __meta_kubernetes_pod_label_cs_(.+)
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [ __meta_kubernetes_namespace ]
                action: replace
                target_label: namespace
              - source_labels: [ __meta_kubernetes_pod_name ]
                action: replace
                target_label: pod
              - source_labels: [ __meta_kubernetes_pod_phase ]
                regex: Pending|Succeeded|Failed|Completed
                action: drop

    pushgateway:
      ## If false, pushgateway will not be installed
      ##
      enabled: false
